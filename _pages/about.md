---
permalink: /
title: "Hi, I'm Negar Kamali."
excerpt: "About me"
layout: single
author_profile: true
redirect_from:
  - /about/
  - /about.html
toc: true
toc_sticky: true
toc_label: "On this page"
---

I'm a fourth-year Ph.D. student in Computer Science at Northwestern University, advised by [Matt Groh](https://mattgroh.com/) and [Jessica Hullman](http://users.eecs.northwestern.edu/~jhullman/). My research focuses on how humans understand and interact with advanced AI systems -- from detecting AI-generated media to making better decisions with AI assistance. I am broadly interested in **AI alignment**, **mechanistic interpretability**, and building tools that help people reason effectively about AI outputs.

Before my current PhD, I completed a Ph.D. in Computational Mechanics, where I developed numerical methods for nonlinear wave propagation PDEs. I also have industry experience as a Software Developer and Automation Expert. [This paper](https://www.sciencedirect.com/science/article/pii/S2589004221006477) sparked my decision to return to academia and study human-AI collaboration.

## Research Interests

- **Human-AI Interaction & Decision-Making** -- How do people use (and misuse) AI advice? How can we design better AI-assisted decision systems?
- **AI-Generated Media Detection** -- Understanding what makes deepfakes convincing and how to help people spot them
- **AI Alignment & Mechanistic Interpretability** -- Making AI systems more transparent, trustworthy, and aligned with human values
- **Uncertainty Quantification in ML** -- Conformal prediction and calibrated uncertainty for human-facing AI

## Selected Publications

**Characterizing Photorealism and Artifacts in Diffusion Model-Generated Images**
Negar Kamali, Karyn Nakamura, Aakriti Kumar, Angelos Chatzimparmpas, Matthew Groh.
*CHI 2025* -- Proceedings of the ACM Conference on Human Factors in Computing Systems.
[Paper](https://doi.org/10.1145/3706598.3713784) | [Demo video](https://youtu.be/PL_ggNzMd-o?si=c8pqfcB3WJU5Ly5O)

**How to Distinguish AI-Generated Images from Authentic Photographs**
Negar Kamali, Karyn Nakamura, Angelos Chatzimparmpas, Jessica Hullman, Matthew Groh.
*arXiv preprint*, 2024.
[Paper](https://arxiv.org/abs/2406.08651)

**Utility of Conformal Prediction Sets for AI-Advised Image Labeling**
Negar Kamali et al.
*CHI 2024* -- Proceedings of the ACM Conference on Human Factors in Computing Systems.
**Best Paper Honorable Mention**
[Paper](https://arxiv.org/abs/2401.08876)

## Current Projects

I am investigating how people detect AI-generated images and what factors make them miss the subtle artifacts these images contain. My work under supervision of [Matt Groh](https://mattgroh.com/) at Kellogg School of Management aims to develop tools and techniques to enhance human ability to distinguish between real and synthetic images. In a world where AI-generated images are increasingly realistic, understanding how people perceive them is crucial for combating misinformation and maintaining trust in visual media.

Think you have what it takes to distinguish real photos from AI generated images? Put your skills to the test on our [DetectFakes](https://detectfakes.kellogg.northwestern.edu/) website!

## News

### Upcoming
- **Talk at UT Austin's AI Literacy Initiative (April 2026)**
  Presenting *"Countering AI-Generated Disinformation on Social Media"*.

### Recent
- **Talk at CODE@MIT 2025 (Nov 2025)**
  Presented *"Do Brief How-To Trainings Improve Human Detection of AI-Generated Images? Evidence from a Randomized Study with Government Analysts"*.

- **CHI 2025** -- Presented *"Characterizing Photorealism and Artifacts in Diffusion Model-Generated Images"*

- **Panelist at AI and Disinformation Summit** (By Invitation), Carnegie Mellon University, Pittsburgh, PA, Jan 2025
- **Talk at Laboratory for Analytical Science Symposium**, North Carolina State University, Raleigh, NC, Dec 2024

## Media Coverage

-  [*New Scientist:* How to Avoid Being Fooled by AI-Generated Misinformation](https://www.newscientist.com/article/2445475-how-to-avoid-being-fooled-by-ai-generated-misinformation/)
-  [*Kellogg Insight:* Can You Tell if These Photos Are AI-Generated?](https://insight.kellogg.northwestern.edu/article/ai-photos-identification?utm_medium=social)
-  [*Mashable:* How to identify AI-generated videos](https://mashable.com/article/how-identify-ai-generated-videos)
-  [*Kellogg Insight:* When Put to the Test, Are We Any Good at Spotting AI Fakes?](https://insight.kellogg.northwestern.edu/article/are-we-any-good-at-spotting-ai-fakes)
-  [*Technology Magazine:* Does Google's Veo 3 Do Enough to Distinguish AI and Reality?](https://technologymagazine.com/articles/does-googles-veo-3-do-enough-to-distinguish-ai-and-reality)
-  [*Asahi*: What to look for to spot fake images? US researchers develop "skill-up site" (In Japanese)](https://globe.asahi.com/article/15886926)

## Past Projects

**Conformal Prediction for AI-Advised Decisions:** I researched enhancing AI-advised decision-making by accurately quantifying prediction uncertainty of deep neural networks. I explored the effectiveness of conformal prediction sets as an alternative to traditional uncertainty measures, measuring how they impact human decisions in real-world image labeling scenarios. This work received a **Best Paper Honorable Mention** at CHI 2024.

**Prenatal Stress Reduction:** In collaboration with the [Center for Advancing Safety of Machine Intelligence (CASMI)](https://casmi.northwestern.edu/), advised by [Maia Jacobs](https://sites.northwestern.edu/nupath/people/), I worked on [co-designing patient-facing machine learning for prenatal stress reduction](https://casmi.northwestern.edu/research/projects/prenatal-stress-reduction.html).
