---
permalink: /
title: "Hi, I'm Negar Kamali."
excerpt: "About me"
layout: single
author_profile: true
redirect_from: 
  - /about/
  - /about.html
toc: true
toc_sticky: true
toc_label: "On this page"
---


I‚Äôm a fourth-year Ph.D. student in the Computer Science department at Northwestern University, advised by Professors [Matt Groh](https://mattgroh.com/) and [Jessica Hullman](http://users.eecs.northwestern.edu/~jhullman/). I am a multidisciplinary researcher motivated by the growing challenges posed by artificial intelligence (AI), particularly as it begins to exceed human abilities to fully understand its processes and outcomes. I focus on addressing the critical need for humans to understand and interact effectively with advanced AI systems, including deepfakes and large language models (LLMs), to enhance human ability to recognize, respond to, and benefit from these technologies.

In my past life, I completed a Ph.D. in Computational Mechanics, during which I developed several advanced numerical methods for solving nonlinear wave propagation PDEs. Following my passion in understanding how AI impacts human decision-making, I began a second Ph.D. in Computer Science at Northwestern University. [This](https://www.sciencedirect.com/science/article/pii/S2589004221006477) sparked my decision to go back to academia and do research on human-AI collaboration.

I also have prior industry experience as a Software Developer and Automation Expert.  

## Current Projects

The main project I am working on is investigating how people detect AI-generated images and what factors make them miss the subtle artifacts and implausibilities these images often contain. This project is under supervision of [Matt Groh](https://mattgroh.com/) with Kellogg School of Management. My research aims to develop tools and techniques to enhance human ability to distinguish between real and synthetic images. In a world where AI-generated images are increasingly realistic, understanding how people perceive them is crucial for combating misinformation and maintaining trust in visual media. This work is published in Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems and another paper is coming out soon! 

Think you have what it takes to distinguish real photos from AI generated images? Put your skills to the test on our [DetectFakes](https://detectfakes.kellogg.northwestern.edu/) website!

## üì∞ News

### Upcoming
- üé§ **Talk at CODE@MIT 2025 (Nov 2025)**  
  Presenting *"Do Brief How-To Trainings Improve Human Detection of AI-Generated Images? Evidence from a Randomized Study with Government Analysts"*.

### Recent
- üìë **CHI 2025** ‚Äì Presented *"Characterizing Photorealism and Artifacts in Diffusion Model-Generated Images"*  
  [üé• Demo video](https://youtu.be/PL_ggNzMd-o?si=c8pqfcB3WJU5Ly5O)

- üéôÔ∏è **Panelist at AI and Disinformation Summit** (By Invitation), Carnegie Mellon University, Pittsburgh, PA, Jan 2025  
- üéôÔ∏è **Talk at Laboratory for Analytical Science Symposium**, North Carolina State University, Raleigh, NC, Dec 2024  

### üì∞ Media Coverage

- üß† [*New Scientist:* How to Avoid Being Fooled by AI-Generated Misinformation](https://www.newscientist.com/article/2445475-how-to-avoid-being-fooled-by-ai-generated-misinformation/)  
- üéì [*Kellogg Insight:* Can You Tell if These Photos Are AI-Generated?](https://insight.kellogg.northwestern.edu/article/ai-photos-identification?utm_medium=social)  
- üé• [*Mashable:* How to identify AI-generated videos](https://mashable.com/article/how-identify-ai-generated-videos)  
- üîç [*Kellogg Insight:* When Put to the Test, Are We Any Good at Spotting AI Fakes?](https://insight.kellogg.northwestern.edu/article/are-we-any-good-at-spotting-ai-fakes)  
- ü§ñ [*Technology Magazine:* Does Google‚Äôs Veo 3 Do Enough to Distinguish AI and Reality?](https://technologymagazine.com/articles/does-googles-veo-3-do-enough-to-distinguish-ai-and-reality)  

## Past Projects

I have researched on enhancing AI-advised decision-making by accurately quantifying the prediction uncertainty of deep Neural Networks (NNs). I explore the effectiveness of conformal prediction sets as an alternative to traditional uncertainty measures, and how they impact human decisions in various real-world scenarios. Specifically, we measured the [Utility of Conformal Prediction Sets for AI-advised Image Labeling](https://arxiv.org/abs/2401.08876). This work is published in Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems and was recognized by a best paper honorable mention award.

Another project I have worked on was in collaboration with the [Center for Advancing Safety of Machine Intelligence (CASMI)](https://casmi.northwestern.edu/) advised by [Maia Jacobs](https://sites.northwestern.edu/nupath/people/) to [Co-Design Patient-Facing Machine Learning for Prenatal Stress Reduction](https://casmi.northwestern.edu/research/projects/prenatal-stress-reduction.html).







